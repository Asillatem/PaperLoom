# =============================================================================
# PaperLoom - Backend Configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
# =============================================================================

# -----------------------------------------------------------------------------
# Database & Storage (defaults work for most setups)
# -----------------------------------------------------------------------------
DATABASE_URL=sqlite:///./paperloom.db
PROJECTS_DIR=./projects
CACHE_DIR=./cache

# -----------------------------------------------------------------------------
# Zotero Cloud API (REQUIRED)
# -----------------------------------------------------------------------------
# Get your credentials at: https://www.zotero.org/settings/keys
# 1. Log in to Zotero
# 2. Go to Settings > Feeds/API
# 3. Create a new private key with read access
# 4. Your User ID is shown at the top of the page
ZOTERO_USER_ID=your_user_id_here
ZOTERO_API_KEY=your_api_key_here

# -----------------------------------------------------------------------------
# CORS Origins (for production/custom deployments)
# -----------------------------------------------------------------------------
# Comma-separated list of allowed origins for API requests
# Default covers standard local development ports
CORS_ORIGINS=http://localhost:5173,http://localhost:3000,http://127.0.0.1:5173,http://127.0.0.1:3000

# -----------------------------------------------------------------------------
# Ollama Configuration (for local LLM)
# -----------------------------------------------------------------------------
# URL where Ollama is running (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# -----------------------------------------------------------------------------
# OpenAI API (optional)
# -----------------------------------------------------------------------------
# Only needed if using OpenAI as your LLM provider instead of Ollama
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=
